{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NourEldin-Osama/T5_Fine-tuning_Text-simplification/blob/main/Notebooks/fine_tuning_t5_Kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets sacrebleu sacremoses huggingface_hub\n",
        "!pip install wandb --upgrade"
      ],
      "metadata": {
        "id": "anmjr9qqIfvD",
        "outputId": "1f2b3d33-9c6d-479b-c847-e9d42c09e615",
        "execution": {
          "iopub.status.busy": "2023-03-23T17:51:08.794035Z",
          "iopub.execute_input": "2023-03-23T17:51:08.794442Z",
          "iopub.status.idle": "2023-03-23T17:51:36.638936Z",
          "shell.execute_reply.started": "2023-03-23T17:51:08.794413Z",
          "shell.execute_reply": "2023-03-23T17:51:36.637647Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.26.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\nCollecting sacrebleu\n  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting sacremoses\n  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.7/site-packages (0.12.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.2.0)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2023.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.3)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.14)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (4.9.2)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (2.7.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses) (1.16.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses) (8.1.3)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses) (1.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.8.2)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.1.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (22.2.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.7.1)\nBuilding wheels for collected packages: sacremoses\n  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=daf48c6918d2de6ac4356cfbe89560f1d36da99510e453fae2ed76e1b70564ee\n  Stored in directory: /root/.cache/pip/wheels/5b/e0/77/05245143a5b31f65af6a21f7afd3219e9fa4896f918af45677\nSuccessfully built sacremoses\nInstalling collected packages: sacrebleu, sacremoses\nSuccessfully installed sacrebleu-2.3.1 sacremoses-0.0.53\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.13.10)\nCollecting wandb\n  Downloading wandb-0.14.0-py3-none-any.whl (2.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.28.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from wandb) (4.4.0)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.15.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from wandb) (59.8.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (8.1.3)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.7/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.30)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (6.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (4.11.4)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (3.11.0)\nInstalling collected packages: wandb\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.13.10\n    Uninstalling wandb-0.13.10:\n      Successfully uninstalled wandb-0.13.10\nSuccessfully installed wandb-0.14.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datasets import load_dataset, load_metric\n",
        "from transformers import (AutoTokenizer, AutoModelForSeq2SeqLM, \n",
        "                          DataCollatorForSeq2Seq,\n",
        "                          Seq2SeqTrainingArguments, Seq2SeqTrainer)\n",
        "import logging\n",
        "\n",
        "\n",
        "logging.disable(logging.INFO) # disable INFO and DEBUG logging everywhere\n",
        "# logging.disable(logging.WARNING) # disable WARNING, INFO and DEBUG logging everywhere"
      ],
      "metadata": {
        "id": "rC4vWkcC0UbK",
        "execution": {
          "iopub.status.busy": "2023-03-23T17:51:36.641613Z",
          "iopub.execute_input": "2023-03-23T17:51:36.642853Z",
          "iopub.status.idle": "2023-03-23T17:51:48.636093Z",
          "shell.execute_reply.started": "2023-03-23T17:51:36.642806Z",
          "shell.execute_reply": "2023-03-23T17:51:48.634687Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-23T17:51:57.862085Z",
          "iopub.execute_input": "2023-03-23T17:51:57.863056Z",
          "iopub.status.idle": "2023-03-23T17:51:57.898630Z",
          "shell.execute_reply.started": "2023-03-23T17:51:57.863019Z",
          "shell.execute_reply": "2023-03-23T17:51:57.897628Z"
        },
        "trusted": true,
        "id": "LKBOqw1teC-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets = load_dataset(\"wiki_auto\", \"manual\")\n",
        "raw_datasets"
      ],
      "metadata": {
        "id": "nQdPlfRlDFWS",
        "outputId": "9f360409-94f1-4602-b451-91265ed3edda",
        "execution": {
          "iopub.status.busy": "2023-03-23T17:52:07.987230Z",
          "iopub.execute_input": "2023-03-23T17:52:07.988087Z",
          "iopub.status.idle": "2023-03-23T17:53:12.114193Z",
          "shell.execute_reply.started": "2023-03-23T17:52:07.988016Z",
          "shell.execute_reply": "2023-03-23T17:53:12.113189Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "a3cbd2cffdee452eac81dc70b4d83876",
            "8213cf6799964771927ef2561479c951",
            "51cd0ac159f4430f8ec7dd54986ea042",
            "1d7e7096d588487e98faa070576a0d04",
            "1f2136d6428347bbae2728962f7d5e14",
            "074f4ec56efa4f4e94e5df75f9a5987c",
            "32bd1c54c65a4d9689c6c5c765b383e9",
            "",
            "b39203938cc4450bb6f79f7e3a3fd1be"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/3.11k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3cbd2cffdee452eac81dc70b4d83876"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading metadata:   0%|          | 0.00/2.47k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8213cf6799964771927ef2561479c951"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Downloading and preparing dataset wiki_auto/manual (download: 161.13 MiB, generated: 158.12 MiB, post-processed: Unknown size, total: 319.25 MiB) to /root/.cache/huggingface/datasets/wiki_auto/manual/1.0.0/eeac705719dc9aa2ff180571dfed6c6649588ccdfde8d45a47d2e47e5c5b93af...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51cd0ac159f4430f8ec7dd54986ea042"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/113M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d7e7096d588487e98faa070576a0d04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/4.00M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f2136d6428347bbae2728962f7d5e14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/4.79M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "074f4ec56efa4f4e94e5df75f9a5987c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32bd1c54c65a4d9689c6c5c765b383e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/373801 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating dev split:   0%|          | 0/73249 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split:   0%|          | 0/118074 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Dataset wiki_auto downloaded and prepared to /root/.cache/huggingface/datasets/wiki_auto/manual/1.0.0/eeac705719dc9aa2ff180571dfed6c6649588ccdfde8d45a47d2e47e5c5b93af. Subsequent calls will reuse this data.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b39203938cc4450bb6f79f7e3a3fd1be"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['alignment_label', 'normal_sentence_id', 'simple_sentence_id', 'normal_sentence', 'simple_sentence', 'gleu_score'],\n        num_rows: 373801\n    })\n    dev: Dataset({\n        features: ['alignment_label', 'normal_sentence_id', 'simple_sentence_id', 'normal_sentence', 'simple_sentence', 'gleu_score'],\n        num_rows: 73249\n    })\n    test: Dataset({\n        features: ['alignment_label', 'normal_sentence_id', 'simple_sentence_id', 'normal_sentence', 'simple_sentence', 'gleu_score'],\n        num_rows: 118074\n    })\n})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets[\"train\"][0]"
      ],
      "metadata": {
        "id": "5mMRRjGCSQst",
        "outputId": "a547ee64-2d02-418b-e93b-c4312be366ec",
        "execution": {
          "iopub.status.busy": "2023-03-23T17:53:12.116181Z",
          "iopub.execute_input": "2023-03-23T17:53:12.117089Z",
          "iopub.status.idle": "2023-03-23T17:53:12.125110Z",
          "shell.execute_reply.started": "2023-03-23T17:53:12.117031Z",
          "shell.execute_reply": "2023-03-23T17:53:12.123915Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'alignment_label': 1,\n 'normal_sentence_id': '0_66252-1-0-0',\n 'simple_sentence_id': '0_66252-0-0-0',\n 'normal_sentence': 'The Local Government Act 1985 is an Act of Parliament in the United Kingdom.',\n 'simple_sentence': 'The Local Government Act 1985 was an Act of Parliament in the United Kingdom.',\n 'gleu_score': 0.800000011920929}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 512\n",
        "prefix = \"simplify: \"\n",
        "\n",
        "def preproces_function(elements):\n",
        "    inputs = [prefix + doc for doc in elements[\"normal_sentence\"]]\n",
        "    outputs = elements[\"simple_sentence\"]\n",
        "    \n",
        "    model_inputs = tokenizer(inputs, text_target=outputs, max_length=max_length, truncation=True)\n",
        "\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "XrT0WhBEVwUr",
        "execution": {
          "iopub.status.busy": "2023-03-23T17:53:12.126715Z",
          "iopub.execute_input": "2023-03-23T17:53:12.127394Z",
          "iopub.status.idle": "2023-03-23T17:53:12.134747Z",
          "shell.execute_reply.started": "2023-03-23T17:53:12.127355Z",
          "shell.execute_reply": "2023-03-23T17:53:12.133664Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"t5-small\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
        "\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(preproces_function, batched=True)\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]"
      ],
      "metadata": {
        "id": "SjUlhd2rWT2v",
        "outputId": "41e17403-8440-4c9f-cf09-3b802f4ee862",
        "execution": {
          "iopub.status.busy": "2023-03-23T17:53:12.137083Z",
          "iopub.execute_input": "2023-03-23T17:53:12.138261Z",
          "iopub.status.idle": "2023-03-23T17:55:26.344422Z",
          "shell.execute_reply.started": "2023-03-23T17:53:12.138141Z",
          "shell.execute_reply": "2023-03-23T17:55:26.343432Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "d90d302cde1e4da88b0d706b00eed465",
            "c4edd8e3f2eb4cefa3cbbf425cd5d3d8",
            "4d02be04334c449dbe072631f63d5ecf",
            "bc27a7dff6a341cd95183b4b89519013",
            "d4a224ae6e284ea0874d4a1ad303e901",
            "d66cd89c3ffe47c897989527bbd4533f",
            "e32ccdcf90c047d6a17645002c61f9e5",
            "e28949b6dad44db28a08cf7dbe1832ab"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d90d302cde1e4da88b0d706b00eed465"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4edd8e3f2eb4cefa3cbbf425cd5d3d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d02be04334c449dbe072631f63d5ecf"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5_fast.py:165: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\nFor now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n  FutureWarning,\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/242M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc27a7dff6a341cd95183b4b89519013"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4a224ae6e284ea0874d4a1ad303e901"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/374 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d66cd89c3ffe47c897989527bbd4533f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/74 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e32ccdcf90c047d6a17645002c61f9e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/119 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e28949b6dad44db28a08cf7dbe1832ab"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# num_train_epochs = 1\n",
        "train_batch_size=16\n",
        "eval_batch_size=16\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=f\"{model_name}-finetuned-text-simplification\",\n",
        "    save_total_limit = 1,\n",
        "    load_best_model_at_end = True,\n",
        "    save_strategy = \"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    include_inputs_for_metrics = True,\n",
        "#     num_train_epochs=num_train_epochs,\n",
        "    overwrite_output_dir = True,\n",
        "    push_to_hub=True,\n",
        "    per_device_train_batch_size=train_batch_size,\n",
        "    per_device_eval_batch_size=eval_batch_size,\n",
        "#     report_to=\"none\",\n",
        "    )"
      ],
      "metadata": {
        "id": "WWlFuI1DBTA6",
        "execution": {
          "iopub.status.busy": "2023-03-23T17:55:26.346401Z",
          "iopub.execute_input": "2023-03-23T17:55:26.346664Z",
          "iopub.status.idle": "2023-03-23T17:55:26.430311Z",
          "shell.execute_reply.started": "2023-03-23T17:55:26.346627Z",
          "shell.execute_reply": "2023-03-23T17:55:26.429395Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric(\"sari\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels, inputs = eval_pred\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    inputs = np.where(inputs != -100, inputs, tokenizer.pad_token_id)\n",
        "\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    decoded_inputs = tokenizer.batch_decode(inputs, skip_special_tokens=True)\n",
        "    \n",
        "    # Some simple post-processing\n",
        "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
        "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
        "    decoded_inputs = [[input.strip()] for input in decoded_inputs]\n",
        "\n",
        "    result = metric.compute(sources=decoded_inputs, predictions=decoded_preds, references=decoded_labels)\n",
        "    print(result)\n",
        "    return result"
      ],
      "metadata": {
        "id": "745L4QbuISt4",
        "outputId": "964cda07-b5e9-4058-d976-d0e147994547",
        "execution": {
          "iopub.status.busy": "2023-03-23T17:55:26.431615Z",
          "iopub.execute_input": "2023-03-23T17:55:26.431980Z",
          "iopub.status.idle": "2023-03-23T17:55:28.078949Z",
          "shell.execute_reply.started": "2023-03-23T17:55:26.431939Z",
          "shell.execute_reply": "2023-03-23T17:55:28.077987Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "4fdf54683d6641bfbd70b72b478edcb2"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/3.55k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fdf54683d6641bfbd70b72b478edcb2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"dev\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "05oidJAmurOW",
        "execution": {
          "iopub.status.busy": "2023-03-23T17:55:28.081626Z",
          "iopub.execute_input": "2023-03-23T17:55:28.081896Z",
          "iopub.status.idle": "2023-03-23T17:55:39.556794Z",
          "shell.execute_reply.started": "2023-03-23T17:55:28.081857Z",
          "shell.execute_reply": "2023-03-23T17:55:39.555597Z"
        },
        "trusted": true,
        "outputId": "eb290ece-e22c-4da2-f92f-3ab24483b524"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Cloning https://huggingface.co/NourEldin-Osama/t5-small-finetuned-text-simplification into local empty directory.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "3Ou_I4OEu3ZC",
        "outputId": "7df2e340-db64-4f04-f8c2-c81db4f91a6c",
        "_kg_hide-output": true,
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2023-03-23T17:55:39.559138Z",
          "iopub.execute_input": "2023-03-23T17:55:39.559431Z",
          "iopub.status.idle": "2023-03-23T20:58:32.900474Z",
          "shell.execute_reply.started": "2023-03-23T17:55:39.559387Z",
          "shell.execute_reply": "2023-03-23T20:58:32.899553Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "  ········································\n"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.14.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20230323_175929-84gdti53</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/memorizers/huggingface/runs/84gdti53' target=\"_blank\">apricot-haze-1</a></strong> to <a href='https://wandb.ai/memorizers/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/memorizers/huggingface' target=\"_blank\">https://wandb.ai/memorizers/huggingface</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/memorizers/huggingface/runs/84gdti53' target=\"_blank\">https://wandb.ai/memorizers/huggingface/runs/84gdti53</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='70089' max='70089' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [70089/70089 2:58:30, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Sari</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.656700</td>\n      <td>4.510199</td>\n      <td>58.185275</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.765500</td>\n      <td>4.911852</td>\n      <td>57.233430</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3.749800</td>\n      <td>4.911852</td>\n      <td>57.233430</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "{'sari': 58.18527507670439}\n{'sari': 57.23342972855014}\n{'sari': 57.23342972855014}\n",
          "output_type": "stream"
        },
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainOutput(global_step=70089, training_loss=2.9121790504681435, metrics={'train_runtime': 10973.1902, 'train_samples_per_second': 102.195, 'train_steps_per_second': 6.387, 'total_flos': 2.4335943078445056e+16, 'train_loss': 2.9121790504681435, 'epoch': 3.0})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(\"End of Training\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-23T21:05:53.032700Z",
          "iopub.execute_input": "2023-03-23T21:05:53.033053Z",
          "iopub.status.idle": "2023-03-23T21:05:56.459573Z",
          "shell.execute_reply.started": "2023-03-23T21:05:53.033007Z",
          "shell.execute_reply": "2023-03-23T21:05:56.458142Z"
        },
        "trusted": true,
        "id": "hWKlV4q6eC-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"t5-finetuned-text-simplification\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-23T21:01:10.634889Z",
          "iopub.execute_input": "2023-03-23T21:01:10.635767Z",
          "iopub.status.idle": "2023-03-23T21:01:46.102139Z",
          "shell.execute_reply.started": "2023-03-23T21:01:10.635708Z",
          "shell.execute_reply": "2023-03-23T21:01:46.100735Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "cc647e5254b5481996f256ddef297102"
          ]
        },
        "id": "Z-_HrvFjeC-W",
        "outputId": "5ca1ccd5-2ff2-4501-d13d-7111a865fc9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Several commits (2) will be pushed upstream.\nThe progress bars may be unreliable.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Upload file runs/Mar23_17-55-26_ce32a332d75e/events.out.tfevents.1679594139.ce32a332d75e.23.0:   0%|          …",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc647e5254b5481996f256ddef297102"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "To https://huggingface.co/NourEldin-Osama/t5-small-finetuned-text-simplification\n   04e3806..7f71071  main -> main",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "To https://huggingface.co/NourEldin-Osama/t5-small-finetuned-text-simplification\n   7f71071..7755f85  main -> main",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After training, access the path of the best checkpoint like this\n",
        "best_checkpoint_path = trainer.state.best_model_checkpoint\n",
        "best_checkpoint_path"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-23T21:02:13.949146Z",
          "iopub.execute_input": "2023-03-23T21:02:13.949705Z",
          "iopub.status.idle": "2023-03-23T21:02:13.960630Z",
          "shell.execute_reply.started": "2023-03-23T21:02:13.949659Z",
          "shell.execute_reply": "2023-03-23T21:02:13.959560Z"
        },
        "trusted": true,
        "id": "IChc8TDveC-X",
        "outputId": "02a82923-1f68-4af4-ba62-0b93734ad6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'t5-small-finetuned-text-simplification/checkpoint-23363'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# best_model = AutoModelForSeq2SeqLM.from_pretrained(best_checkpoint_path)\n",
        "# best_model.push_to_hub(\"t5-small-finetuned-text-simplification\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "HKM4lYUveC-X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
